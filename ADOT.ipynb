{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2540fd12-1063-45ec-8ad0-f2f78bd03807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3207f3-0390-45b4-ba7b-ab33924e91cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 17 elements, new values have 21 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39mdf\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mtuple\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;28mtuple\u001b[39m(main_header)])]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Set the proper header\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m df_cleaned\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m main_header\n\u001b[1;32m     17\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m df_cleaned[df_cleaned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoc ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoc ID\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Remove any remaining header duplicates\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Store the cleaned DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[0;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[1;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 17 elements, new values have 21 elements"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the Excel file\n",
    "file_path = '/Users/kishupatel/Desktop/DesFert/ADOT/2019-AADT-PUBLICATION.xlsx'\n",
    "dfs = pd.read_excel(file_path, sheet_name=None, header=None)  # Read without assuming a header initially\n",
    "\n",
    "# Define the main header row\n",
    "main_header = ['Loc ID', 'Route', 'BMP', 'Start', 'TCS MP', 'EMP', 'End', 'Pos Dir AADT', 'Neg Dir AADT', 'AADT 2018', 'AADT Derivation Code', \n",
    "               'K Factor%' , 'D Factor%' , 'AADT Motorcyles', 'AADT Passenger Cars','AADT Light Trucks', 'AADT Buses' ,'AADT Single Trucks', 'AADT Combo Trucks', 'T Factor %', '2040 Future AADT']  # Replace with actual column names\n",
    "\n",
    "# Process each sheet\n",
    "cleaned_sheets = {}\n",
    "for sheet_name, df in dfs.items():\n",
    "    # Remove additional header rows that match the main header\n",
    "    df_cleaned = df[~df.apply(tuple, axis=1).isin([tuple(main_header)])]\n",
    "\n",
    "    # Set the proper header\n",
    "    df_cleaned.columns = main_header\n",
    "    df_cleaned = df_cleaned[df_cleaned['Loc ID'] != 'Loc ID']  # Remove any remaining header duplicates\n",
    "\n",
    "    # Store the cleaned DataFrame\n",
    "    cleaned_sheets[sheet_name] = df_cleaned\n",
    "\n",
    "# Save all cleaned sheets to a new Excel file\n",
    "cleaned_file_path = '/Users/kishupatel/Desktop/DesFert/ADOT/CLEANED.xlsx'\n",
    "with pd.ExcelWriter(cleaned_file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name, df_cleaned in cleaned_sheets.items():\n",
    "        df_cleaned.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01961aae-22a9-409c-b98f-96e0e1d49fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet name: CNTLOCID\n",
      "0    100001\n",
      "1    100002\n",
      "2    100003\n",
      "3    100004\n",
      "4    100005\n",
      "Name: CNTLOCID, dtype: int64\n",
      "----------------------------------------\n",
      "Sheet name: ROUTE\n",
      "0    I 8\n",
      "1    I 8\n",
      "2    I 8\n",
      "3    I 8\n",
      "4    I 8\n",
      "Name: ROUTE, dtype: object\n",
      "----------------------------------------\n",
      "Sheet name: BMP\n",
      "0    0.00\n",
      "1    0.50\n",
      "2    2.24\n",
      "3    3.98\n",
      "4    7.60\n",
      "Name: BMP, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: START\n",
      "0    California State Line - Yuma\n",
      "1             Exit 1 Giss Parkway\n",
      "2          Exit 2 US 95 / 16th St\n",
      "3       Exit 3 SR 280 / Avenue 3E\n",
      "4                 Exit 7 Araby Rd\n",
      "Name: START, dtype: object\n",
      "----------------------------------------\n",
      "Sheet name: TCS MP\n",
      "0    0.30\n",
      "1    1.71\n",
      "2    2.60\n",
      "3    5.80\n",
      "4    8.30\n",
      "Name: TCS MP, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: EMP\n",
      "0    0.50\n",
      "1    2.24\n",
      "2    3.98\n",
      "3    7.60\n",
      "4    9.40\n",
      "Name: EMP, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: END\n",
      "0                                Exit 1 Giss Parkway\n",
      "1                             Exit 2 US 95 / 16th St\n",
      "2                          Exit 3 SR 280 / Avenue 3E\n",
      "3                                    Exit 7 Araby Rd\n",
      "4    Exit 9 SB 8 (1) / Avenue 8 1/2 E - East of Yuma\n",
      "Name: END, dtype: object\n",
      "----------------------------------------\n",
      "Sheet name: Length\n",
      "0    0.50\n",
      "1    1.74\n",
      "2    1.74\n",
      "3    3.62\n",
      "4    1.80\n",
      "Name: Length, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: POS Dir AADT\n",
      "0        NaN\n",
      "1    12120.0\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "Name: POS Dir AADT, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: NEG Dir AADT\n",
      "0        NaN\n",
      "1    11145.0\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "Name: NEG Dir AADT, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: AADT 2011\n",
      "0    18652\n",
      "1    23313\n",
      "2    24446\n",
      "3    29343\n",
      "4    28147\n",
      "Name: AADT 2011, dtype: int64\n",
      "----------------------------------------\n",
      "Sheet name: AADT Derivation Code\n",
      "0    2.0\n",
      "1    1.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    2.0\n",
      "Name: AADT Derivation Code, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: K Factor \n",
      "0    12.0\n",
      "1     9.0\n",
      "2    12.0\n",
      "3    12.0\n",
      "4    12.0\n",
      "Name: K Factor , dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: D Factor \n",
      "0    58.0\n",
      "1    55.0\n",
      "2    58.0\n",
      "3    58.0\n",
      "4    58.0\n",
      "Name: D Factor , dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: Single Truck\n",
      "0    1100.0\n",
      "1    1249.0\n",
      "2    1430.0\n",
      "3    1678.0\n",
      "4    1595.0\n",
      "Name: Single Truck, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: Combo Truck\n",
      "0    1860.0\n",
      "1    2790.0\n",
      "2    2418.0\n",
      "3    2837.0\n",
      "4    2697.0\n",
      "Name: Combo Truck, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: T Factor \n",
      "0    16.0\n",
      "1    17.0\n",
      "2    16.0\n",
      "3    15.0\n",
      "4    15.0\n",
      "Name: T Factor , dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: b\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: b, dtype: float64\n",
      "----------------------------------------\n",
      "Sheet name: Click Headers and Derivation Codes to view definitions/meanings\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: Click Headers and Derivation Codes to view definitions/meanings, dtype: float64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Read all sheets into a dictionary of DataFrames\n",
    "file_path = '/Users/kishupatel/Desktop/DesFert/ADOT/2011-AADT-PUBLICATION.xls'\n",
    "dfs = pd.read_excel(file_path, sheet_name=None)\n",
    "#dfs = pd.read_excel(file_path, sheet_name=None, header=0, skiprows=range(0, 4))  # Skips the first 4 rows(header defines number row assigned to header)\n",
    "for sheet_name, df in dfs.items():\n",
    "    print(f\"Sheet name: {sheet_name}\")\n",
    "    print(df.head())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3f17e26-f172-47b4-9974-17d51b63a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_ids = [100022, 100023, 100085, 100086, 100088, 100100, 100101, 100102, 100112, 100113, 100117, 100348, 100677, 100678, 100679, \n",
    "             100918, 100980, 100982, 101240, 101385, 101597, 101598, 101599, 101600, 101890, 101891, 101902, 101903, 101904] \n",
    "\n",
    "\n",
    "# Specify the columns you want to retrieve\n",
    "columns_to_select = ['Loc ID', 'Route', 'Start', 'End', 'AADT 2011']\n",
    "#columns_to_select = ['Loc ID', 'Road', 'FromRoad', 'ToRoad', 'AADT 2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465a659-b459-473d-88a8-12f0a74e94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all combined data into 1 sheet\n",
    "\n",
    "output_directory = '/Users/kishupatel/Desktop'  # Your desired directory\n",
    "output_file_name = 'filtered_output1.xlsx'  # The desired file name\n",
    "output_file_path = os.path.join(output_directory, output_file_name)\n",
    "all_filtered_data = []\n",
    "\n",
    "# Loop through each sheet\n",
    "for sheet_name, df in dfs.items():\n",
    "    # Check if the required columns are in the sheet\n",
    "    if all(col in df.columns for col in columns_to_select):\n",
    "        # Filter rows where 'Loc ID' is in the list of given Loc IDs and select specific columns\n",
    "        filtered_data = df[df['Loc ID'].isin(given_ids)][columns_to_select]\n",
    "        \n",
    "        if not filtered_data.empty:  # Only append non-empty data\n",
    "            all_filtered_data.append(filtered_data)\n",
    "    else:\n",
    "        print(f\"Columns {columns_to_select} not found in sheet: {sheet_name}\")\n",
    "\n",
    "# Combine all filtered data into one DataFrame\n",
    "combined_data = pd.concat(all_filtered_data, ignore_index=True)\n",
    "\n",
    "# Remove duplicates from the combined data\n",
    "combined_data = combined_data.drop_duplicates()\n",
    "\n",
    "# Create an ExcelWriter object to write the output to a new Excel file\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    # Write the combined data to a single sheet\n",
    "    combined_data.to_excel(writer, sheet_name='CombinedData', index=False)\n",
    "\n",
    "print(f\"Filtered data has been written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daf482-1460-400b-8a35-2f8b9cd8faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprated data into seprate sheet\n",
    "output_directory = '/Users/kishupatel/Desktop'  # Your desired directory\n",
    "output_file_name = 'filtered_output.xlsx'  # The desired file name\n",
    "output_file_path = os.path.join(output_directory, output_file_name)\n",
    "\n",
    "\n",
    "# Create an ExcelWriter object to write the output to a new Excel file\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    sheet_written = False  # Flag to track if any sheet is written\n",
    "    \n",
    "    # Loop through each sheet\n",
    "    for sheet_name, df in dfs.items():\n",
    "        # Check if the required columns are in the sheet\n",
    "        if all(col in df.columns for col in columns_to_select):\n",
    "            # Filter rows where 'Loc ID' is in the list of given Loc IDs and select specific columns\n",
    "            filtered_data = df[df['Loc ID'].isin(given_ids)][columns_to_select]\n",
    "            \n",
    "            if not filtered_data.empty:  # Only write if data exists\n",
    "                # Write the filtered data to a new sheet in the output file\n",
    "                filtered_data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                sheet_written = True\n",
    "        else:\n",
    "            print(f\"Columns {columns_to_select} not found in sheet: {sheet_name}\")\n",
    "    \n",
    "    if not sheet_written:\n",
    "        print(\"No data was written to the output file. Please check your filters and input file.\")\n",
    "    else:\n",
    "        print(f\"Filtered data has been written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6cb70-c9c1-4a30-ac5b-38a7f9e843f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
